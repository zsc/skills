已按你给的“和 kimi claw 的一个早晨”内容，整理成 `skill.md`（可直接放进仓库当使用手册/个人 SOP）。

[下载 skill.md](sandbox:/mnt/data/skill.md)

---

````md
# Kimi Claw 使用手册（skill.md）

> 面向：把 Kimi Claw 当作“云端不睡觉的小伙伴/实验助理”，用于**跑实验、管队列、做提醒、写总结、推送新闻**。  
> 入口：`https://www.kimi.com/bot`  
> 关键词：**queue.md + 定时提醒 + 机器自检 + 跑批产物 + 反馈迭代**  
> 备注：不同版本/权限下能力会变化；本文以“能在云端执行命令/读写文件/推送提醒/输出报告”为默认前提。

---

## 0. 你要的不是“聊天机器人”，而是一台“会汇报的云主机”

Kimi Claw 的最佳用法不是让它回答问题，而是让它形成闭环：

1. **你丢一个目标**（例如“把 v3_tts_bug_finder 改到 indextts2 本地 server”）
2. **它先自检环境**（CPU/内存/磁盘/GPU/网络）
3. **它执行任务**（跑批、记录日志、生成报告）
4. **它按约定汇报**（一句话状态 + 关键指标 + 产物路径）
5. **你插一句反馈/加塞**（比如“再做 ablation / 再跑久一点 / 加上 cifar-100 验证”）
6. 循环。

想让它“不闲着”，核心是两件事：

- **持久任务队列**：`queue.md`（让它永远有活干）
- **定时提醒**：你不盯屏幕也不会错过节点（“3h 后提醒我处理 gpuhub4”）

---

## 1. 快速上手：第一次打开就做三件事

### 1.1 让它做一次“机器体检”
让 Kimi Claw 执行并总结以下命令输出（它可以自己补充）：

- `uname -a`
- `cat /proc/cpuinfo` 或 `lscpu`
- `free -m`
- `df -h`
- （有 GPU 时）`nvidia-smi`

让它用**一句话**总结，例如：

> 这是一台配备 Intel Xeon Platinum、内存约 4GB、磁盘约 40GB 的 Ubuntu 服务器；磁盘/内存占用较低，整体状态健康。（示例）

> 小贴士：把这句话写进 `env.md`，以后复盘/迁移环境很省心。

### 1.2 建一个 `queue.md`，把“想做但没空盯”的事都扔进去
推荐格式（简单好用）：

```md
# queue.md

## P0（今天必须推进）
- [ ] 任务名：……（产物：report.html / logs/*.log）
  - 背景：……
  - 验收：……
  - 预计运行：>= 3h（到点提醒）

## P1（本周推进）
- [ ] ……

## P2（想法池）
- [ ] ……
````

### 1.3 立刻开一个“3h 实验 + 到点提醒”

你的目标是尽快把流程跑通：**启动长任务 → GPU 不闲 → 有产物 → 有提醒**。

---

## 2. 日常工作流：一个“和 Kimi Claw 的早晨”

你可以把早晨例行流程固化成一个 prompt，让它每天自动给你“早安包”。

### 2.1 早安包模板（可直接复制）

* 机器状态（1 句话）
* 昨晚/正在跑的实验状态（进度、预计完成点、异常）
* 今日 AI 新闻（按你的兴趣过滤，带发布时间）
* queue.md 的 P0/P1 里最该推进的一条建议
* 生活提醒（喝水/早餐/香蕉/刷牙等）

示例提示词：

> 早安。请输出今日早安包：
>
> 1. 运行 uname/free/df（有 GPU 再跑 nvidia-smi），用一句话总结机器健康；
> 2. 汇报 queue.md 中正在进行/阻塞的任务（最多 5 条）；
> 3. 按我的研究兴趣给 3 条 AI 新闻，每条写“发布时间 + 为什么相关”；
> 4. 8:00 提醒我喝水、吃香蕉、刷牙。

> 反馈机制：如果新闻不对味，直接“喷一句 + 给参考（如 Scholar/项目列表）”，它就会收敛到你想看的方向。

---

## 3. 跑实验：让 GPU 永远别闲着（但要可控）

### 3.1 核心原则：先约定“产物”，再跑

每次让它跑实验，务必明确：

* **运行入口**：命令/脚本
* **运行时长/停止条件**：至少跑多久、遇到什么错误停
* **产物路径**：例如

  * `report.html`：可视化报告（音频对比/side-by-side）
  * `logs/*.log`：运行日志
  * `report.md`：结论 & 下一步
* **汇报格式**：一句话结论 + 关键指标 + 复现命令

### 3.2 “不盯屏幕也放心”的监工方式

你可以让它：

* 开 `watch nvidia-smi`（或定时抓取显存/利用率）
* 每隔 N 分钟写一次简短心跳到 `logs/heartbeat.log`
* 异常时立即推送提醒（例如 OOM、loss 爆炸、进程退出）

### 3.3 典型任务：把既有项目改造成“跑批收集边缘样例”

示例（来自真实工作流）：

> 将 `~/autodl-tmp/v3_tts_bug_finder` 改成针对 **IndexTTS2 本地 server** 的实验。
> 先阅读 `README.md` 里沉淀的经验教训（例如 ASR 可能出繁体、不要误判等），然后：
>
> * 多跑几轮、跑久一点
> * 收集“高有趣的边缘案例”（最容易暴露 bug 的那类）
> * 输出 `report.html` 和 `logs/*.log`
> * 最后写一个 `summary.md`：本轮最值钱的 10 个案例 + 下一步建议

这类任务特别适合 Kimi Claw：它能在云端持续跑、持续记、持续汇报，你只需要在关键节点插一句方向修正。

---

## 4. 做研究协作：把 Kimi Claw 当“实验经理”，把 Codex/你自己当“实施者”

一个很稳的分工是：

* **Kimi Claw**：排队、跑批、拉日志、写总结、做提醒、推送新闻（偏“运营/调度”）
* **Codex/你**：改模型/写代码/做大改动（偏“开发/研究”）

### 4.1 ablation/验证类任务的标准下发方式

你给的指令越“工程化”，它越不容易跑偏。建议包含：

* 固定其它设置（seed、epochs、数据集、量化配置等）
* 只动一个因素（AdamW vs SGD、grad clip、pooling、patch-norm…）
* 输出对齐指标（best val / test、实验目录名、可复现命令）
* 把结论写进 `report.md` 的具体位置（最好带行号或章节名）

示例提示词（可复制）：

> 请做 ablation：AdamW / weight decay / grad clip / mean pooling / patch-norm。
> 约束：其余超参保持不变；每项至少跑 10 epochs；记录 best val 和 test。
> 产物：更新 report.md（写清“结论是否泛化”与下一步），并在 sweeps/ 下保存每次运行目录。

### 4.2 “结论是否泛化”的惯用追问

当你看到一个 toy 结论（比如“AdamW 很关键”），直接把泛化验证也塞给它：

* CIFAR-10 / CIFAR-100 全量验证
* 或换一个架构/数据增强设置
* 或做 Muon 等替代优化器对照

一句话版本：

> Muon 实验之后，把在 SVHN 上得到的重要结论，在 CIFAR-10 和 CIFAR-100 上全量验证一遍。

---

## 5. AI 新闻推送：别要“热闹”，要“跟你有关 + 不过时”

### 5.1 开启推送后，立刻做两次校准

1. 让它先给你默认 AI 新闻
2. 你马上指出问题（例如“Step-Audio 2 不是去年的吗？”）

然后补充你的“兴趣画像”，例如：

* 你的 Scholar 主页/关键词（或论文列表）
* 你最近在做但还没发表的方向（只写主题，不必写细节）
* 你希望新闻的粒度（3 条/8 条、要不要论文链接、要不要代码仓库）

### 5.2 新闻输出规范（推荐你强制它遵守）

每条新闻必须包含：

* **发布时间/时间范围**
* **一句话摘要**
* **与你的方向的关联理由**
* （可选）可信来源（论文/官方博客/代码仓库）

这样能极大减少“旧闻翻炒”。

---

## 6. Chrome Tab Relay / 本地控制：能不用就不用（安全 + 稳定性）

实践里最容易翻车的一类功能是“远程控制本地浏览器/投影/设备”：

* 连接可能断
* 本地环境复杂
* 权限/安全风险高（“它要是能控制本地 Chrome，有点吓人”）

建议策略：

* **云端负责计算与整理**（跑实验、写报告、抓日志）
* **本地负责交互与展示**（投影、浏览器、视频）

如果一定要做 tab relay，把它当“锦上添花”，并准备**手动 fallback**。

---

## 7. 环境与网络：装包慢、Google 不通、GitHub 可用时的生存方式

你可能遇到：

* pip 安装慢（需要代理/国内镜像）
* GitHub 能访问，但 Google 不通（疑似白名单）

可用的策略：

* 让它把代理写进 shell profile（或在命令前显式 export）
* pip 使用镜像（例如为当前会话配置 `pip config set global.index-url ...`）
* 对外检索优先用：GitHub README、arXiv、各大实验室/公司官方博客（能访问的前提下）

> 目标不是“全网畅通”，而是“足够把实验跑起来”。

---

## 8. 提醒系统：把“我会忘”的事交给它

两类提醒最有价值：

1. **实验提醒**：N 小时后提醒我看结果 / 做下一步（最关键）
2. **生活提醒**：8:00 喝水/吃香蕉/刷牙（别笑，真有用）

写提醒时建议包含：

* 触发时间（固定时间/相对时间）
* 触发内容（明确到动作）
* 是否重复（每天/仅一次）
* （可选）附带状态（例如“同时汇报 queue.md P0 进度”）

---

## 9. Prompt 模板库（直接复制）

### 9.1 机器状态一句话总结

> 请运行 uname -a、free -m、df -h（有 GPU 再 nvidia-smi）。
> 然后用**一句话**总结：CPU/内存/磁盘/GPU/网络是否健康；再给一个“今天是否适合跑长实验”的判断。

### 9.2 追加队列并启动长实验

> 请把以下任务写入 queue.md（P0）：……
> 然后立即启动实验（命令：……），至少跑 3 小时。
> 到点提醒我，并给出：当前进度、关键指标、产物路径（report.html/logs）。

### 9.3 跑 bug finder / 边缘案例收集

> 针对项目 X：先读 README.md 的经验教训并列出你将遵守的 5 条规则；
> 然后跑 N 轮，目标是收集最“奇怪/容易错”的案例；
> 输出 report.html + logs + summary.md（Top 10 案例，附复现步骤）。

### 9.4 ablation 研究单

> 做 ablation：因素列表……
> 固定其它设置……
> 每个实验输出：best val、test、运行目录名、复现命令；
> 最后在 report.md 写“结论 + 是否可能泛化 + 下一步”。

### 9.5 AI 新闻按兴趣过滤（防过时）

> 从你能访问的来源汇总今日 AI 新闻，**只保留与以下关键词相关**：……
> 每条必须写：发布时间、摘要、为什么相关。
> 如果信息可能过时，请明确标注“可能过时/待核实”。

---

## 10. 最终检查清单（你只要看这 10 条）

* [ ] 它会先自检机器，再动手
* [ ] 有 `queue.md`，而且它会维护状态
* [ ] 每个长任务都有：入口命令、产物路径、汇报格式
* [ ] GPU 不闲：有监控（nvidia-smi/心跳）
* [ ] 到点会提醒（3h/固定时间）
* [ ] 日志可追：`logs/` 清晰
* [ ] 报告可读：`report.html` 或 `report.md`
* [ ] 新闻不过时：每条带发布时间 + 相关性
* [ ] 本地控制功能能不用就不用（安全 + 稳定）
* [ ] 你可以随时“加塞一句话”改变优先级，而不用重开一局

---

## 附：最短的“一句话哲学”

> Kimi Claw = 一台云主机 + 一个会写总结/会提醒的实验经理；
> 你只需要不断把“下一步”塞进 queue.md，然后让它按时把你叫醒。

```
```
